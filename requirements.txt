llama-cpp-python>=0.2.24
pyyaml>=6.0
fastapi==0.111.0
uvicorn[standard]==0.30.0
